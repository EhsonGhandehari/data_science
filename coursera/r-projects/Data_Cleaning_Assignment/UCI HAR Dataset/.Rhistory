my_data<-read.csv("/Users/EhsonMG/documents/temporary/hw1_data.csv")
my-data
my_data
str(my_data)
read.csv("/Users/EhsonMG/documents/temporary/hw1_data.csv", nrows=151:153)
read.csv("/Users/EhsonMG/documents/temporary/hw1_data.csv", skip=151)
read.csv("/Users/EhsonMG/documents/temporary/hw1_data.csv", header=TRUE, skip=151)
read.csv("/Users/EhsonMG/documents/temporary/hw1_data.csv", nrows>151)
read.csv("/Users/EhsonMG/documents/temporary/hw1_data.csv", rows>151)
read.csv("/Users/EhsonMG/documents/temporary/hw1_data.csv", row.names>151)
read.csv("/Users/EhsonMG/documents/temporary/hw1_data.csv", row.names=151, nrows=2)
read.csv("/Users/EhsonMG/documents/temporary/hw1_data.csv", row.names=151)
read.csv("/Users/EhsonMG/documents/temporary/hw1_data.csv")
my_data
str(my_data)
my_data[1]
my_data(1,)
my_data[1,]
my_data[151:153,]
my_data[47,]
arguments(readline)
attributes(readlin)
attributes(readline)
readLines("/Users/EhsonMG/documents/temporary/hw1_data.csv", n>151)
readLines("/Users/EhsonMG/documents/temporary/hw1_data.csv", n=151)
str(my_data)
summary(my_data)
42.13*153
6445.89/(153-37)
my_data$Ozone
my_data2<-my_data$Ozone>31 & my_data$Temp>90
my_data2
my_data3<-my_data(my_data2)
my_data3<-my_data[my_data2]
my_data[my_data2]
mv my_data2
rv my_data2
my_data3<-my_data(c(my_data2))
my_data2[TRUE]
my_data("/Users/EhsonMG/documents/temporary/hw1_data.csv")
my_data<-read.csv("/Users/EhsonMG/documents/temporary/hw1_data.csv")
my_data
my_data2$Ozone>31
my_data$Ozone>31
sel_1<-c("Ozone")
Sel_1
sel_1
sel_1<-c(my_data$Ozone)
sel_1
remove (sel_1)
my_data2<-(my_data$Ozone<32 & my_data$Temp<91)<-0
my_data$Ozone
my_data("Ozone">31 & "Temp">91)
my_data2<-subset(my_data, Ozone>31 & Temp>90)
my_data2
summary
str(my_data2)
summary(my_data2)
remove (my_data2)
my_data2<-subset(my_data, Month==5)
my_data2
summary(my_data)
summary(my_data2)
remove my_data2
remove (my_data2)
my_data2<-subset(my_data, Month==6)
summary(my_data2)
my_data3<-subset(my_data, Month==5)
summary(my_data3)
add2<-function(x,y){
x+y
}
add2(3,5)
above<-function (a,n){
use<-a>n
a[use]
}
x<-1:20
above(x,12)
install.packages("KernSmooth")
library(KernSmooth)
source('~/Documents/Learning/R/specdata/corr.R')
pollutantmean("specdata", "sulfate", 1:10)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
pollutantmean("specdata", "sulfate", 1:10)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml",destfile="/Users/EhsonMG/Documents/Coursera/Data Science/cleaning_data/data.xml",method="curl")
install.packages("xml")
install.packages("XML")
library(XML)
data<-xmlTreeParse("/Users/EhsonMG/Documents/Coursera/Data Science/cleaning_data/data.xml")
top<-xmlRoot(data)
xmlName(top)
names(top)
names(top[[1]][[1]])
names(top[[1]][[1]][["zipcode"]])
names(top[[1]][[1]][["zipcode"]][["text"]])
zipcode<-names(top[[1]][[1]][["zipcode"]][["text"]])
zipcode<-names(top[[1]][[1]][["zipcode"]])
xmlSApply(zipcode,xmlValue)
xmlSApply(zipcode, function(x) xmlSApply(x, xmlValue))
zipcode<-names(top[[1]][[1]][["zipcode"]][["text"]])
names(top[[1]][[1]][["name"]])
names(top[[1]][[1]])
names(top[[1]][[1]][["zipcode"]])
art<-top[[1]][[1]]
art
art[1]
art<-top[[1]]
art
xmlSApply(art[[2]],xmlValue)
xmlSApply(art[[3]],xmlValue)
art<-top[[1]][["zipcode"]]
art<-top[[1]]
xmlSApply(art,xmlValue)
xmlSApply(art[["zipcode"]],xmlValue)
data<-xmlParse("/Users/EhsonMG/Documents/Coursera/Data Science/cleaning_data.xml")
data<-xmlParse("/Users/EhsonMG/Documents/Coursera/Data Science/cleaning_data/data.xml")
data
data$row
data[1]
Node<-xmlNode(data)
Node
top<-xmlRoot(data)
top
names(top[[1]])
names(top[[1]][[1]])
top<-top[[1]][[1]])
top<-top[[1]][[1]]
top
top[1]
top<-top[[1]]
top
top<-xmlRoot(data)
level1<-top[[1]]
level1
level1[1]
level1[1][[1]]
level1[[1]][[1]]
xmlSApply(level1,"zipcode",xmlValue)
xmlSApply(level1,zipcode,xmlValue)
xmlValue(level1[["//zipcode"]])
xmlValue(data[["//zipcode"]])
xpathApply(level1,"//zipcode",xmlValue)
xpathApply(level1,"//zipcode[@zipcode='21231']",xmlValue)
xpathApply(level1,"//zipcode[@zipcode]",xmlValue)
xpathApply(level1,"//zipcode",xmlValue)
xpathApply(level1,//zipcode,xmlValue)
xpathApply(level1,"//zipcode",xmlValue)=='21231'
sum(xpathApply(level1,"//zipcode",xmlValue)=='21231')
sum(xpathApply(data,"//zipcode",xmlValue)=='21231')
download.file("http://www.pythonlearn.com/code/mbox-short.txt",destfile="/Users/ehson/Downloads/mbox-short.txt")
download.file("http://www.pythonlearn.com/code/mbox-short.txt",destfile="/Users/ehson/Downloads/mbox-short.txt",method="curl")
download.file("http://www.pythonlearn.com/code/mbox-short.txt",destfile="/Users/EhsonMG/Downloads/mbox-short.txt",method="curl")
download.file("http://www.pythonlearn.com/code/romeo.txt",destfile="'/Users/EhsonMG/Downloads/romeo.txt")
download.file("http://www.pythonlearn.com/code/romeo.txt",destfile="'/Users/EhsonMG/Downloads/romeo.txt",method="curl")
download.file("http://www.pythonlearn.com/code/romeo.txt",destfile="/Users/EhsonMG/Downloads/romeo.txt",method="curl")
rnorm(200)
n<-100
x=rnoem(n)
x=rnorm(n)
x2=rnorm(n)
x3=rnorm(n)
y=1+x+x2+x3+rnorm(n,sd=0.1)
y
y
y
ey=resid(lm(y~x2+x3))
ey
ex=resid(lm(x~x2+x3))
sum(ey*ex)/sum(ex^2)
library(swirl)
install_from_swirl("Regression Models")
swirl
swirl()
plot(child~parent,galton)
plot(jitter(child,4)~parent,galton)
regrline<-lm(child~parent,galton)
abline(regrline,lwd=3,col='red')
summary(regrline)
fit<-lm(child~parent,dataset=galton)
fit<-lm(child~parent,data=galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals,galton$paren)
cov(fit$residuals,galton$parent)
ols.ic<-fit$coef[1]
ols.slope<-fit$coef[2]
rhs-lhs
lhs-rhs
all.equal(lhs,rhs)
var(child)
var(galton$child)
varChild<-var(galton$child)
varRes<-var(fit$residuals)
varEst<-var(est)
varEst<-var(est(ols.slope,ols.ic))
all.equal(varChild,varEst+varRes)
View(attenu)
View(attenu)
efit <- lm(accel ~ mag+dist,attenu)
mean(efit$residuals)
cov(efit$residuals,attenu$mag)
cov(efit$residuals,attenu$dis)
cov(efit$residuals,attenu$dist)
cor(gch_nor,gpa_nor)
l_nor<-lm(gch_nor~gpa_nor)
2
swirl()
fit<-lm(child~parent,galton)
sum(fit$residulas^2)/(n-2)
sqrt(sum(fit$residulas^2))/(n-2)
sqrt(sum(fit$residulas^2)/(n-2))
sqrt(sum(fit$residuals^2)/(n-2))
summary(fit)
summary(fit)$sigma
deviance(fit)/(n-w)
deviance(fit)/(n-2)
sqrt(deviance(fit)/(n-2))
mu<-mean(child)
mu<-mean(galton$child)
sTot<-sum((galton$child-mean(galton$child))^2)
sTot<-sum((galton$child-mu^2)
sTot<-sum((galton$child-mu)^2)
sRes<-sum(fit$residuals^2)
sRes<-deviance(fit)
1-sRes/sTot
summary(fit)$r
summary(fit)$r.squared
cor(child~parent,galton)^2
with(galton,cor(child~parent)^2)
cor(galton$child,galton$parent)^2
swirl()
library(swirl)
swirl()
ones<-rep(1,nrow(galton))
lm(child~ones+parent-1,galton)
lm(child~parent,galton)
lm(child~1,galton)
head(trees)
fit<-lm(Volume!Girth+Height+Constant-1,trees)
fit<-lm(Volume~Girth+Height+Constant-1,trees)
trees2<-eliminate("Girth",trees)
head(trees2)
fit2<-lm(Volume~Height+Constant-1,trees2)
lapply(list(fit,fit2,coef))
lapply(list(fit,fit2),coef))
lapply(list(fit,fit2),coef)
update.packages()
update.packages()
install.packages("evaluate")
library("jsonlite", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
update.packages()
plot(cars)
M=[7 0 2 1 0 0 1;1 7 0 0 2 0 1;1 0 0 0 7 1 2;0 2 0 0 7 1 1]
M<-[7 0 2 1 0 0 1;1 7 0 0 2 0 1;1 0 0 0 7 1 2;0 2 0 0 7 1 1]
M<-[7 0 2 1 0 0 1;1 7 0 0 2 0 1;1 0 0 0 7 1 2;0 2 0 0 7 1 1]
[7 0 2 1 0 0 1;1 7 0 0 2 0 1;1 0 0 0 7 1 2;0 2 0 0 7 1 1]
c(7 0 2 1 0 0 1 1 7 0 0 2 0 1 1 0 0 0 7 1 2 0 2 0 0 7 1 1)
c(7,0,2,1,0,0,1,1,7,0,0,2,0,1,1,0,0,0,7,1,2,0,2,0,0,7,1,1)
matrix(c(7,0,2,1,0,0,1,1,7,0,0,2,0,1,1,0,0,0,7,1,2,0,2,0,0,7,1,1),ncol=7,nrow=4)
matrix(c(7,0,2,1,0,0,1,1,7,0,0,2,0,1,1,0,0,0,7,1,2,0,2,0,0,7,1,1),ncol=4,nrow=7)
x<-matrix(c(7,0,2,1,0,0,1,1,7,0,0,2,0,1,1,0,0,0,7,1,2,0,2,0,0,7,1,1),ncol=4,nrow=7)
x
l<-c(1,3,2,1,2,1,1)
l
l*x
sum(l*x)
sum(l*x)[1]
summary(l*x)
colSums(l*x)
# Making two files: test_data and train_data
# opening plyr package.
library("plyr")
library("tidyr")
setwd("/Users/ehson/Downloads/UCI HAR Dataset")
All_files<-list.files(path=".",recursive=TRUE)  # Reading all the text files in
library("plyr")
install.packages("plyr")
library("tidyr")
install.packages("tidyr")
setwd("/Users/ehson/Downloads/UCI HAR Dataset")
parent.frame()
print(getwd())
m=getwd()
get(m,envir=parent.frame())
get(m,envir=parent.frame())
get('m',envir=parent.frame())
remove(m)
parent.frame(2)$ofile
parent.frame(2)$ofile
dirname(parent.frame(2)$ofile)
utils::getSrcDirectory()
utils::getSrcDirectory()[1]
dirname(rstudioapi::getActiveDocumentContext()$path)
install.packages("rstudioapi")
library("rstudioapi")
dirname(rstudioapi::getActiveDocumentContext()$path)
rstudioapi::getActiveDocumentContext()$path
rstudioapi::getActiveDocumentContext()$path
system("pwd",intern=T)
dirname(parent.frame(2)$ofile)
print(getwd())
source_pathname  = get("ofile",envir = parent.frame())
source_dirname = dirname(source_pathname )
setwd(source_dirname)
print(getwd())
ls()
m=2
ls()
remove m
remove m
remove(m)
sys.frame(1)$ofile
sys.frames(0)
sys.nframe()
sys.frames(0)
sys.frames
sys.frames()
source("run_analysis.R", chdir = T)
~/active-rstudio-document
source(run_analysis.R)
source("run_analysis.R")
source("run_analysis.R", chdir = T)
gwd()
gwd()
getwd()
system(find /Users -name "run_analysis.R",intern=TRUE)
system("find /Users -name "run_analysis.R",intern=TRUE)
system(find /Users -name run_analysis.R,intern=TRUE)
system("find /Users -name run_analysis.R",intern=TRUE)
# Making two files: test_data and train_data
# Installing the necesary packages and loading them.
require(plyr, quietly=TRUE, warn.conflicts=FALSE)
require(tidyr, quietly=TRUE, warn.conflicts=FALSE)
library("plyr")
library("tidyr")
address<-system("find /Users -name run_analysis_EMG.R",intern=TRUE)
address
setwd(address)
type(address)
classes(address)
class(address)
attributes(address)
address
address$status
m<-address
m
m-"/run_analysis-EMG"
address[0]
address[1]
address[2]
address[3]
address[1]
setwd(address[1])
?regex
address[1][1]
address[1][0]
address[1](1)
m<-lenght("run_analysis_EMG.R")
m<-length("run_analysis_EMG.R")
m
m<-nchar("run_analysis_EMG.R")
m<--1*(nchar("run_analysis_EMG.R"))
length1<-nchar(address)
length2<-(nchar("run_analysis_EMG.R"))
length2<nchar("run_analysis_EMG.R")
strtrim(address, length1-length2)
strtrim(address, length1-length2)[1]
address<-system("find /Users -name run_analysis_EMG.R",intern=TRUE)
length1<-nchar(address)
length2<-nchar("run_analysis_EMG.R")+1
strtrim(address, length1-length2)[1]
address<-strtrim(address, length1-length2)[1]
setwd(address)
All_files<-list.files(path=".",recursive=TRUE)  # Reading all the text files in
variables_name<-read.table(All_files[3])
datax_train<-read.table(All_files[27])
colnames(datax_train)<-as.character(variables_name[,2])
datay_train<-read.table(All_files[28])
subjects<-read.table(All_files[26])
colnames(subjects)[1]<-"subject"
colnames(datay_train)[1]<-"activity"
Train<-cbind(datay_train,subjects,datax_train)
datax_test<-read.table(All_files[15])
colnames(datax_test)<-as.character(variables_name[,2])
datay_test<-read.table(All_files[16])
subjects<-read.table(All_files[14])
colnames(subjects)[1]<-"subject"
colnames(datay_test)[1]<-"activity"
Test<-cbind(datay_test,subjects,datax_test)
# Step 1. Merges the training and the test sets to create one data set.
Total_data<-rbind(Test,Train)
# Step 2. Selecting the columns with mean and standard deviation
colnumbers<-c(1:2,sort(c(grep("mean",colnames(Total_data),ignore.case=TRUE),grep("std",colnames(Total_data),ignore.case=TRUE))))
ms<-Total_data[,colnumbers]
# Step 3. changing factor levels 1:6 as activity to descriptive levels
ms$activity<-as.factor(ms$activity)
levels(ms$activity)<-c("Walking","Walking_upstairs","Walking_downstairs","Sitting","Standing","Laying")
# Step 5 From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
# Writting it into
data_tidy<-m<-ddply(ms,.(subject,activity),function(x) apply(x[,3:88],2,mean))
write.table(data_tidy,file="data_tidy.txt",row.name=FALSE)
data_tidy<-ddply(ms,.(subject,activity),function(x) apply(x[,3:88],2,mean))
write.table(data_tidy,file="data_tidy.txt",row.name=FALSE)
# Making two files: test_data and train_data
# Installing the necesary packages and loading them.
require(plyr, quietly=TRUE, warn.conflicts=FALSE)
require(tidyr, quietly=TRUE, warn.conflicts=FALSE)
library("plyr")
library("tidyr")
address<-system("find /Users -name run_analysis_EMG.R",intern=TRUE)
length1<-nchar(address)
length2<-nchar("run_analysis_EMG.R")+1
address<-strtrim(address, length1-length2)[1]
setwd(address)
All_files<-list.files(path=".",recursive=TRUE)  # Reading all the text files in
variables_name<-read.table(All_files[3])  # read all the variable names.
datax_train<-read.table(All_files[27])
colnames(datax_train)<-as.character(variables_name[,2])
datay_train<-read.table(All_files[28])
subjects<-read.table(All_files[26])
colnames(subjects)[1]<-"subject"
colnames(datay_train)[1]<-"activity"
Train<-cbind(datay_train,subjects,datax_train)
View(Train)
datax_test<-read.table(All_files[15])
colnames(datax_test)<-as.character(variables_name[,2])
datay_test<-read.table(All_files[16])
subjects<-read.table(All_files[14])
colnames(subjects)[1]<-"subject"
colnames(datay_test)[1]<-"activity"
Test<-cbind(datay_test,subjects,datax_test)
Total_data<-rbind(Test,Train)
colnumbers<-c(1:2,sort(c(grep("mean",colnames(Total_data),ignore.case=TRUE),grep("std",colnames(Total_data),ignore.case=TRUE))))
ms<-Total_data[,colnumbers]
View(ms)
ms$activity<-as.factor(ms$activity)
levels(ms$activity)<-c("Walking","Walking_upstairs","Walking_downstairs","Sitting","Standing","Laying")
View(ms)
ddply(ms,.(subject,activity),function(x) apply(x[,3:88],2,mean))
View(ms)
View(Total_data)
dim(Total_data)
View(ms)
All_files
View(Train)
variables_name
View(Train)
colnumbers<-c(1:2,sort(c(grep("mean",colnames(Total_data),ignore.case=TRUE),grep("std",colnames(Total_data),ignore.case=TRUE))))
Total_data[,colnumbers]
sort(c(grep("mean",colnames(Total_data),ignore.case=TRUE)
grep("std",colnames(Total_data),ignore.case=TRUE)
sort(c(grep("mean",colnames(Total_data),ignore.case=TRUE)
colnames(Total_data)
View(variables_name)
address
address<-system("find /Users -name run_analysis_EMG.R",intern=TRUE)
length1<-nchar(address)
length2<-nchar("run_analysis_EMG.R")+1
address<-paste0(strtrim(address, length1-length2)[1],"/UCI HAR Dataset")
address
setwd(address)
All_files<-list.files(path=".",recursive=TRUE)  # Reading all the text files in
variables_name<-read.table(All_files[3])  # read all the variable names.
# Making two files: test_data and train_data
# Installing the necesary packages and loading them.
require(plyr, quietly=TRUE, warn.conflicts=FALSE)
require(tidyr, quietly=TRUE, warn.conflicts=FALSE)
library("plyr")
library("tidyr")
# finds the location of this active R script on the user computer and sets
# the working directory to files location. Note: this is written for an OS device.
address<-system("find /Users -name run_analysis_EMG.R",intern=TRUE)
length1<-nchar(address)
length2<-nchar("run_analysis_EMG.R")+1
address<-paste0(strtrim(address, length1-length2)[1],"/UCI HAR Dataset")
setwd(address)
All_files<-list.files(path=".",recursive=TRUE)  # Reading all the text files in
variables_name<-read.table(All_files[3])  # read all the variable names.
# Combining the activity list with trained x-data
# change of column names
# step 4, adding descriptive colnames is done here.
datax_train<-read.table(All_files[27])
colnames(datax_train)<-as.character(variables_name[,2])
datay_train<-read.table(All_files[28])
subjects<-read.table(All_files[26])
colnames(subjects)[1]<-"subject"
colnames(datay_train)[1]<-"activity"
Train<-cbind(datay_train,subjects,datax_train)
# Combining the activity list with test x-data
# change of column names
# step 4, adding descriptive colnames is done here.
datax_test<-read.table(All_files[15])
colnames(datax_test)<-as.character(variables_name[,2])
datay_test<-read.table(All_files[16])
subjects<-read.table(All_files[14])
colnames(subjects)[1]<-"subject"
colnames(datay_test)[1]<-"activity"
Test<-cbind(datay_test,subjects,datax_test)
# Step 1. Merges the training and the test sets to create one data set.
Total_data<-rbind(Test,Train)
# Step 2. Selecting the columns with mean and standard deviation
colnumbers<-c(1:2,sort(c(grep("mean",colnames(Total_data),ignore.case=TRUE),grep("std",colnames(Total_data),ignore.case=TRUE))))
ms<-Total_data[,colnumbers]
# Step 3. changing factor levels 1:6 as activity to descriptive levels
ms$activity<-as.factor(ms$activity)
levels(ms$activity)<-c("Walking","Walking_upstairs","Walking_downstairs","Sitting","Standing","Laying")
# Step 5 From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
# Writting it into
data_tidy<-m<-ddply(ms,.(subject,activity),function(x) apply(x[,3:88],2,mean))
write.table(data_tidy,file="data_tidy.txt",row.name=FALSE)
